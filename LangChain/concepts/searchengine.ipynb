{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Engine with Tools and Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://python.langchain.com/docs/integrations/tools/\n",
    "\n",
    "### Tools\n",
    "Tools are interfaces that an agent, chain or LLm can use to inteact with the world. They combine a few things:\n",
    "- The name of the tool\n",
    "- A description of what that tool is\n",
    "- JSON schema of what the inputs to the tool are\n",
    "- The function to call\n",
    "- Whether the rsult of a tool should be returned directly to the user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tool creation\n",
    "- in-build tools: for wikipedia, arxiv and many more\n",
    "- creating custm tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'c:\\\\Users\\\\srish\\\\anaconda3\\\\envs\\\\langchain\\\\lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Page: Mukesh Ambani\\nSummary: Mukesh Dhirubhai Ambani (born 19 April 1957) is an Indian billionaire businessman who is the chairman and managing director of Reliance Industries. He is the richest perso'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in-built tools\n",
    "# wikipedia\n",
    "from langchain.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "wiki_api_wrapper=WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=200)\n",
    "wikipedia=WikipediaQueryRun(api_wrapper=wiki_api_wrapper)\n",
    "print(wikipedia)\n",
    "\n",
    "wikipedia.run(\"mukesh ambani\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Published: 2021-03-29\\nTitle: \"Weak AI\" is Likely to Never Become \"Strong AI\", So What is its Greatest Value for us?\\nAuthors: Bin Liu\\nSummary: AI has surpassed humans across a variety of tasks such as image\\nclassification, playing '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in-built tools\n",
    "# arxiv\n",
    "from langchain.tools import ArxivQueryRun\n",
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "\n",
    "arxiv_api_wrapper=ArxivAPIWrapper(top_k_results=1,doc_content_chars_max=230)\n",
    "arxiv=ArxivQueryRun(api_wrapper=arxiv_api_wrapper)\n",
    "arxiv.run(\"Generative AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating custom tools for RAG\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"HF_TOKEN\"]=os.getenv(\"HF_TOKEN\")\n",
    "hug_embeddings=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "loader=WebBaseLoader(\"https://docs.smith.langchain.com/\")\n",
    "web_loader=loader.load()\n",
    "txt_splitter=RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=200)\n",
    "chunks=txt_splitter.split_documents(web_loader)\n",
    "faiss_vector=FAISS.from_documents(chunks,hug_embeddings)\n",
    "retriever=faiss_vector.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangSmith-Search'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in order to use the retriever as a tool we need to convert it in a tool\n",
    "# now to create tool we need to convert this retriever into tool\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool=create_retriever_tool(retriever,\"LangSmith-Search\",\"Search anything about Langsmith\")\n",
    "retriever_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'c:\\\\Users\\\\srish\\\\anaconda3\\\\envs\\\\langchain\\\\lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200)),\n",
       " ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=230)),\n",
       " Tool(name='LangSmith-Search', description='Search anything about Langsmith', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x00000205C07B7700>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000020581B16670>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n'), coroutine=functools.partial(<function _aget_relevant_documents at 0x00000205C07B7C10>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000020581B16670>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n'))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools=[wikipedia,arxiv,retriever_tool]\n",
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://python.langchain.com/docs/concepts/agents/\n",
    "\n",
    "### Agents\n",
    "The core idea of agents is to use a language model to choose a sequence of actions to take. In chains, a sequence of actions is hardcoded. In agents, a language model is used as a reasoning to determine which actions to take and in which order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### run all the tools with agents and LLM\n",
    "\n",
    "to combine tools with LLM and then exceute them, we need AgentExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "groq_llm=ChatGroq(model=\"Llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference :https://python.langchain.com/v0.1/docs/modules/agents/agent_types/openai_functions_agent/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new way of creating prompt template using hub\n",
    "from langchain import hub\n",
    "\n",
    "prompt=hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
